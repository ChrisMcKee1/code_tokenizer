Metadata-Version: 2.2
Name: code-tokenizer
Version: 0.1.0
Summary: Transform your codebase into LLM-ready tokens with intelligent processing
Home-page: https://github.com/yourusername/code_tokenizer
Author: Your Name
Author-email: Chris McKee <your.email@example.com>
License: MIT License
        
        Copyright (c) 2024 Chris McKee (CodeTokenizer)
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE. 
Project-URL: Homepage, https://github.com/ChrisMcKee1/code-tokenizer
Project-URL: Documentation, https://github.com/ChrisMcKee1/code_tokenizer#readme
Project-URL: Repository, https://github.com/ChrisMcKee1/code_tokenizer.git
Project-URL: Issues, https://github.com/ChrisMcKee1/code_tokenizer/issues
Keywords: llm,tokenizer,code-analysis,documentation,cli
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Software Development :: Documentation
Classifier: Environment :: Console
Classifier: Intended Audience :: Developers
Classifier: Operating System :: OS Independent
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: tiktoken
Requires-Dist: pygments
Requires-Dist: rich
Requires-Dist: pathspec
Requires-Dist: python-dotenv
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: isort; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: requires-python

# ğŸ“š Code Tokenizer

<div align="center">

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Version](https://img.shields.io/badge/version-1.0.0-green.svg)](https://github.com/ChrisMcKee1/code_tokenizer/releases)

[â­ Star](https://github.com/ChrisMcKee1/code_tokenizer) | 
[ğŸ´ Fork](https://github.com/ChrisMcKee1/code_tokenizer/fork) | 
[ğŸ› Report Bug](https://github.com/ChrisMcKee1/code_tokenizer/issues/new?template=bug_report.md&title=[BUG]) | 
[âœ¨ Request Feature](https://github.com/ChrisMcKee1/code_tokenizer/issues/new?template=feature_request.md&title=[FEATURE])

</div>

## ğŸ”„ Your AI-Powered Code Analysis Companion
> Transform any codebase into LLM-ready tokens!

<div align="center">

### âš¡ One Command = LLM-Ready Code Context

```bash
code-tokenizer -d ./your-project -o ./context.md
```



### ğŸ†š Manual Copying vs Code Tokenizer

| Without Code Tokenizer | With Code Tokenizer |
|----------------------|-------------------|
| âŒ Manually copy each file | âœ… One command for entire codebase |
| âŒ Hit token limits constantly | âœ… Automatically fits context window |
| âŒ Miss important code context | âœ… Preserves all critical relationships |
| âŒ Include test/build noise | âœ… Smart filtering of irrelevant files |
| âŒ Waste time formatting | âœ… Perfect LLM-ready format instantly |
| âŒ Inconsistent results | âœ… Consistent, reproducible output |

</div>

## ğŸ“„ What You Get: Perfect LLM Input

- **A Single Markdown/JSON File**: Contains your entire codebase context, perfectly formatted for any LLM
- **Token-Optimized**: Automatically fits within your LLM's context window (GPT-4, Claude, etc.)
- **Ready to Copy & Paste**: Just copy the output file directly into ChatGPT, Claude, or any other LLM
- **Smart Filtering**: Excludes tests, builds, and other noise that confuses LLMs
- **Context Preservation**: Maintains critical relationships between code components

> [!IMPORTANT]
> Stop wasting time manually copying files or hitting token limits. Get your entire codebase into LLMs instantly!

<details open>
<summary><h3 style="display: inline-block; margin: 0;">ğŸ‘€ Example Output (context.md)</h3></summary>

Here's what you get in your output file:

````
# ğŸ“ Project Overview
Your entire codebase, perfectly formatted for LLMs:

## API Components
```typescript
// UserController.ts
export class UserController {
    async getUser(id: string): Promise<User> {
        // Your actual implementation
    }
}
```

## Business Logic
```typescript
// UserService.ts
export class UserService {
    // Your actual business rules
}
```

## Data Models
```typescript
// User.ts
export interface User {
    id: string;
    // Your actual model
}
```

## ğŸ”— Relationships
- Controllers â†’ Services â†’ Models
- Security & Auth flows
- Business rules & validation
````

</details>

> [!TIP]
> Just copy the entire contents of context.md and paste into any LLM. No formatting needed!

## ğŸš€ Installation & Quick Start

<details open>
<summary>ğŸ“¥ Get Started in Seconds</summary>

```bash
# Using pipx (recommended)
pipx install code-tokenizer

# Or using pip
pip install --user code-tokenizer

# Basic usage
code-tokenizer -d ./your-project -o ./context.md
```

</details>

## ğŸ® Usage Examples

<details open>
<summary>Powerful Options for Any Workflow</summary>

```bash
# Generate context from your project
code-tokenizer -d ./your-project -o ./context.md

# Export as JSON for automation
code-tokenizer -d ./your-project -o ./context.json --format json

# Generate context with specific LLM token counting
code-tokenizer -d ./src -o ./context.md --model gpt-4o      # OpenAI's gpt-4o
code-tokenizer -d ./src -o ./context.md --model claude-3   # Anthropic's Claude
code-tokenizer -d ./src -o ./context.md --model gemini-pro # Google's Gemini

# Process multiple directories
code-tokenizer -d ./frontend/src -o ./frontend-context.md
code-tokenizer -d ./backend/src -o ./backend-context.md

# Target specific file types
code-tokenizer -d ./src -o ./typescript-context.md --include "*.ts"
code-tokenizer -d ./src -o ./react-context.md --include "*.tsx"

# Exclude specific patterns
code-tokenizer -d . -o ./context.md --exclude "test/**/*"
code-tokenizer -d . -o ./context.md --exclude "*.test.ts"

# Combine multiple options
code-tokenizer -d ./src \
    -o ./context.md \
    --model gpt-4o \
    --include "*.{ts,tsx}" \
    --exclude "test/**/*" \
    --format markdown \
    --max-tokens 4000
```

</details>

## ğŸ¯ Features & Benefits

### ğŸ¤– LLM Integration
- Perfect for copying code directly into ChatGPT, Claude, or other LLMs
- Formats code to fit any LLM's context window
- Optimized for OpenAI's Models (GPT-4o, o1, o3-mini), Anthropic's (Claude 3.5 Sonnet), Google's (Gemini 1.5 Pro), and more!
- Prevents token limit issues automatically
- Manages token counts to stay within model limits

### ğŸ¨ Smart Processing
- Auto-detects programming languages and encodings
- Respects `.gitignore` rules to exclude irrelevant files
- Handles large codebases efficiently

### ğŸ“Š Analysis & Export
- Provides detailed codebase statistics
- Exports as Markdown or JSON
- Tracks token usage across your project

## ğŸ“‹ Command Options

| Option | Description | Default |
|--------|-------------|---------|
| `-d, --directory` | Source directory | Required |
| `-o, --output` | Output file | Required |
| `--model` | LLM model | claude-3-sonnet |
| `--format` | Output format | markdown |
| `--max-tokens` | Token limit per file | 2000 |

## ğŸ¯ Project Examples

<details open>
<summary><h3 style="display: inline-block; margin: 0;">âš›ï¸ Next.js/React Project</h3></summary>

#### ğŸ“Ÿ CLI Commands

```bash
# Extract context from frontend codebase
code-tokenizer -d ./nextjs-app/src -o ./context/frontend.md --model claude-3

# Process component directory for LLM
code-tokenizer -d ./nextjs-app/src/components -o ./context/components.md --include "*.tsx"
```

#### ğŸ“ Project Structure

```plaintext
nextjs-app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ features/
â”‚   â””â”€â”€ lib/
â”œâ”€â”€ public/
â”œâ”€â”€ node_modules/
â”œâ”€â”€ package.json
â””â”€â”€ .gitignore  # Critical for excluding node_modules
```

#### ğŸ“ Example .gitignore

```gitignore
# Example .gitignore
node_modules/
.next/
out/
build/
.env*.local
*.log
.DS_Store
```

</details>

<details open>
<summary><h3 style="display: inline-block; margin: 0;">ğŸ Python FastAPI Project</h3></summary>

#### ğŸ“Ÿ CLI Commands

```bash
# Extract context from API codebase
code-tokenizer -d ./python-api/src -o ./context/api.md --model gpt-4o

# Process route handlers for LLM
code-tokenizer -d ./python-api/src/api/routes -o ./context/routes.md
```

#### ğŸ“ Project Structure

```plaintext
python-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â””â”€â”€ users.py
â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ security.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ user.py
â”‚       â””â”€â”€ base.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ api/
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore  # Important for excluding env files & pycache
```

#### ğŸ“ Example .gitignore

```gitignore
__pycache__/
*.py[cod]
*$py.class
.env
.venv
venv/
.pytest_cache/
.coverage
```

</details>

<details open>
<summary><h3 style="display: inline-block; margin: 0;">ğŸ¯ C# API with Blazor</h3></summary>

#### ğŸ“Ÿ CLI Commands

```bash
# Extract context from backend codebase
code-tokenizer -d ./dotnet-app/src/Api -o ./context/api.md

# Process Blazor UI components for LLM
code-tokenizer -d ./dotnet-app/src/Client/Pages -o ./context/ui.md

# Extract context from shared models
code-tokenizer -d ./dotnet-app/src/Shared/Models -o ./context/models.md
```

#### ğŸ“ Project Structure

```plaintext
dotnet-app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Api/
â”‚   â”‚   â”œâ”€â”€ Controllers/
â”‚   â”‚   â”œâ”€â”€ Services/
â”‚   â”‚   â””â”€â”€ Program.cs
â”‚   â”œâ”€â”€ Client/
â”‚   â”‚   â”œâ”€â”€ Pages/
â”‚   â”‚   â””â”€â”€ Shared/
â”‚   â””â”€â”€ Shared/
â”‚       â””â”€â”€ Models/
â”œâ”€â”€ tests/
â”œâ”€â”€ .gitignore
â””â”€â”€ global.json
```

#### ğŸ“ Example .gitignore

```gitignore
bin/
obj/
.vs/
*.user
appsettings.*.json
wwwroot/
node_modules/
```

</details>

## ğŸ”§ Troubleshooting

> [!IMPORTANT]
> Common issues and quick fixes:

- **Command not found**: Restart terminal or use `python -m code_tokenizer`
- **Files skipped**: Check file size (<1MB) and `.gitignore` rules
- **Permission issues**: Ensure write access to output directory
- **Installation problems**: Try using a virtual environment

## ğŸ¤ Contributing

1. Fork the repo
2. Create a branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

Made with â¤ï¸ by developers, for developers

[â­ Star Code Tokenizer](https://github.com/ChrisMcKee1/code_tokenizer)
</div>
